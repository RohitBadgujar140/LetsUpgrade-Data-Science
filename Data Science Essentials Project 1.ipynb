{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                #if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                #    df[col] = df[col].astype(np.float16)\n",
    "                #el\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #else:\n",
    "            #df[col] = df[col].astype('category')\n",
    " \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data=pd.read_csv(\"train_V2.csv\")\n",
    "train_data= reduce_mem_usage(train_data)\n",
    "\n",
    "test_data=pd.read_csv(\"/content/test_V2.csv\")\n",
    "test_data= reduce_mem_usage(test_data)\n",
    "\n",
    "train_data.head()\n",
    "\n",
    "train_data.groupby([\"matchType\"]).count()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "train_data.groupby('matchId')['matchType'].first().value_counts().plot.bar()\n",
    "\n",
    "new_train_data=train_data\n",
    "def mapthematch(data):\n",
    "  mapping = lambda y: 'solo' if ('solo' in y) else 'duo' if('duo' in y) or ('crash' in y) else 'squad'\n",
    "  data['matchType'] = data['matchType'].apply(mapping)\n",
    "  return(new_train_data)\n",
    "data=mapthematch(new_train_data)\n",
    "data.groupby('matchId')['matchType'].first().value_counts().plot.bar()\n",
    "data[data['winPlacePerc'].isnull()]\n",
    "data.drop(2744604, inplace=True)\n",
    "\n",
    "\n",
    "data['killsNormalization'] = data['kills']*((100-data['kills'])/100 + 1)\n",
    "data['damageDealtNormalization'] = data['damageDealt']*((100-data['damageDealt'])/100 + 1)\n",
    " \n",
    " \n",
    "data['maxPlaceNormalization'] = data['maxPlace']*((100-data['maxPlace'])/100 + 1)\n",
    " \n",
    "data['matchDurationNormalization'] = data['matchDuration']*((100-data['matchDuration'])/100 + 1)\n",
    "\n",
    "data['healsandboostsfeature'] = data['heals'] + data['boosts']\n",
    "data[['heals', 'boosts', 'healsandboostsfeature']].tail()\n",
    "\n",
    "data['totalDistancetravelled'] = data['rideDistance'] + data['walkDistance'] + data['swimDistance']\n",
    "data[['rideDistance', 'walkDistance', 'swimDistance',totalDistancetravelled]].tail()\n",
    "\n",
    "data['headshot_rate'] = data['headshotKills'] / data['kills']\n",
    "Data['headshot_rate']\n",
    "\n",
    "x=data[['killsNormalization', 'damageDealtNormalization','maxPlaceNormalization', 'matchDurationNormalization','healsandboostsfeature','totalDistancetravelled']]\n",
    "#drop the target variable\n",
    "y=data['winPlacePerc']\n",
    " \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 42) \n",
    "\n",
    "linear=LinearRegression()\n",
    "\n",
    "y_pred=linear.predict(xtest)\n",
    "\n",
    "df1 = df.head(25)\n",
    "df1.plot(kind='bar',figsize=(26,10))\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
